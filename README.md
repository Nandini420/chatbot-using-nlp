# create_chatbot_using_python
This code is an implementation of a simple chatbot using TensorFlow, which is a machine learning framework developed by Google. The chatbot is trained using a neural network to classify user inputs into predefined intents and provide appropriate responses based on the detected intent.
The intents.json file is the data that we will provide to our chatbot 
and the chatbot is trained using neural network to classify user inputs in predefined intents Android appropriate responses based on the detected intake and the code starts by importing the necessary libraries including numpy tensorflow and ltk the word net limitizer from the analytical library is used to reduce words to the base to improve classification accuracy that is called limitize the code also loads the intense.
json file which contains the predefined intents and Associated patterns and responses now the code then prepares the data for training by iterating through each pattern in the intense.json file tokenizing it into individual words limitizing the words and adding them to a list called words in each pattern and its Associated intent are also added to a list called documents additionally a list called classes is created to store the different intents next the words list is clean by removing any punctuation characters and duplicates and then sorted alphabetically similarly the classes list are sorted these clean and sorted lists are saved to files called words.pkl and classes Dot pkl respectively using the Picker Library and the code then I did through the documents list and converts each pattern into Bag upwards that is a list of binary values indicating whether each word in the words is list is present or not in the pattern the corresponding intent for each pattern is also converted into a one hole encoded Vector indicating which intent it belongs to these bag of words and one hot encoded
vectors are then combined and added to a list called training the training list is then shuffled randomly to ensure the neural network does not learn any older dependencies in the training data finally the training list is converted into a numpy array and split into separate arrays from the bag of words that is train X and one hot encoded vectors that is train y you can see them and the neural network is defined using the tensorflow sequential API which allows the layers to be added in the sequence the neural network consists of three fully connected layers the First with 128 nodes the second one is 64 nodes and third with the number of nodes equal to the number of classes the first two layers also include drop out regularization with a dropout rate of 0.5 which helps to prevent overfitting the model is compiled using stochastic gradient descent that is SGD as the optimizer and categorical cross entropy as the loss function the accuracy Matrix is also calculated during training finally the model is trained for 200 epochs with a batch size of 5 and verbose set to 1 to display progress during print after training the model is saved to a file that is chatbot underscore simply learned dot H5 along with its training history and the program Trends execute to indicate that the training is complete now we'll move to chatbot.